{
 "metadata": {
  "name": "",
  "signature": "sha256:e685dede968be9468c2a5c5667356271482b1d0e2eb261af9356e90dea156aca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import Bio \n",
      "import re\n",
      "import sys\n",
      "from Bio import SeqIO\n",
      "from Bio.Blast import NCBIXML\n",
      "from Bio import Restriction \n",
      "from Bio.Restriction import *\n",
      "from Bio.Alphabet.IUPAC import IUPACAmbiguousDNA\n",
      "from Bio.Seq import Seq\n",
      "from Bio.SeqRecord import SeqRecord\n",
      "from Bio.Blast.Applications import NcbiblastnCommandline\n",
      "from Bio import SeqFeature\n",
      "from Bio.SeqFeature import *\n",
      "import random\n",
      "import itertools\n",
      "import multiprocessing"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "import operator\n",
      "\n",
      "def al_plot_complexity(list):\n",
      "    '''\n",
      "    Takes a list of sequences, plots count of sequences vs percent of unique sequences.\n",
      "    '''\n",
      "    c = Counter(list)\n",
      "    freqs = []\n",
      "    for item in c:\n",
      "       freqs.append((c[item], c))\n",
      "    sorted_c = sorted(c.items(), key=operator.itemgetter(1))\n",
      "    x = xrange(0, len(sorted_c))\n",
      "    counts = []\n",
      "    for item, count in sorted_c:\n",
      "        counts.append(count)\n",
      "    global rangelist\n",
      "    rangelist = [a/100.0 for a in xrange(0, 100, 2)]\n",
      "    y = []\n",
      "    for p in rangelist:\n",
      "        a, l = int(len(counts)*p), len(counts)\n",
      "        y.append(float(sum(counts[l-a:l]))/sum(counts)*100)\n",
      "    zip(y, rangelist)\n",
      "    %pylab inline\n",
      "    figure()\n",
      "    plot(rangelist, y, \"o\")\n",
      "    xlabel(\"Cumulative fraction of unique spacers\")\n",
      "    ylabel(\"Percent of total reads (molecules) in library\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def al_string2feat(queryseq, ampsdict): #lib5pr is subjectseq; t7 is queryseq\n",
      "    '''\n",
      "    This function accepts a query seq and a dictionary of subjectseqs, where the key (amp)\n",
      "    is contained in a field in queryseq, highlighting the location of queryseq in it. \n",
      "    Returns a string.\n",
      "    '''\n",
      "    subjectseq = SeqRecord(ampsdict[queryseq[1][0]])\n",
      "    #for seqrecord in subjectseq:\n",
      "    locstart = queryseq[1][1]\n",
      "    #print queryseq\n",
      "    locend = queryseq[1][2]\n",
      "    fwdlocs = []  \n",
      "    revlocs = []\n",
      "    # Figure out which strand the BLAST hit is on\n",
      "    if locstart <= locend:\n",
      "        fwdlocs.append(locstart)\n",
      "    if locstart > locend:\n",
      "        revlocs.append(locend)\n",
      "    \n",
      "    for item in fwdlocs:\n",
      "        start = ExactPosition(int(item))\n",
      "        end = ExactPosition(int((item) + len(queryseq[0].seq) + 1))\n",
      "        location = FeatureLocation(start, end)\n",
      "        feature = SeqFeature(location,type=str(\"cutsite_fwd\"), strand = +1)\n",
      "        subjectseq.features.append(feature)\n",
      "\n",
      "    for item in revlocs:\n",
      "        start = ExactPosition(int(item))\n",
      "        end = ExactPosition(start + len(queryseq[0].seq))\n",
      "        location = FeatureLocation(start, end)\n",
      "        feature = SeqFeature(location,type=str(\"cutsite_rev\"), strand = -1)\n",
      "        subjectseq.features.append(feature)\n",
      "    #print subjectseq.features\n",
      "    return subjectseq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def al_print_features(inputseq, addpamcutters, directlabel):\n",
      "    '''\n",
      "    Takes 3 arguments:\n",
      "    inputseq: SeqRecord to draw\n",
      "    addpamcutters: int - 0 or 1. If 1, also draw HpaII/BfaI/ScrFI sites on map.\n",
      "    directlabel: int, 0 or 1. Recommend 1. Changes position of feature labels (1 = on markings, 0 = below them)\n",
      "    '''\n",
      "    if addpamcutters == 1:\n",
      "        cutline = list(\" \" * len(inputseq))\n",
      "        HpaIIsites = HpaII.search(inputseq.seq)\n",
      "        BfaIsites = BfaI.search(inputseq.seq)\n",
      "        ScrFIsites = ScrFI.search(inputseq.seq)\n",
      "        for cut in HpaIIsites:\n",
      "            cutline[cut-1:cut + len(\"HpaII\")] = \"<HpaII\"\n",
      "        for cut in BfaIsites:\n",
      "            cutline[cut-1:cut + len(\"BfaI\")] = \"<BfaI\"\n",
      "        for cut in ScrFIsites:\n",
      "            cutline[cut-1:cut + len(\"ScrFI\")] = \"<ScrFI\"\n",
      "        cutline = \"\".join(cutline)\n",
      "    \n",
      "    \n",
      "    mask = [list(((\"-\" * 9) + \"^\" )* int(round(len(inputseq.seq)/10.0)))]\n",
      "    newmaskline = list(((\"-\" * 9) + \"^\" )* int(round(len(inputseq.seq)/10.0)))\n",
      "\n",
      "    for feature in inputseq.features:\n",
      "        # Make a new marker strand if any features overlap. All marker strands can be elements of a list.\n",
      "        featstart = int(feature.location.start)\n",
      "        featend = int(feature.location.end)\n",
      "        if featstart > featend:\n",
      "            print(\"Error! Feature end must be after feature start. Use strand to specify direction! Feature \" + feature.type + \\\n",
      "                  \" will not be displayed!\")\n",
      "        #if \"<\" in mask[-1][featstart:featend] or \">\" in mask[-1][featstart:featend]:\n",
      "            #mask.append(newmaskline)\n",
      "\n",
      "        clean = 0\n",
      "        for item in mask[-1][featstart:featend]:\n",
      "            if item == \"-\":\n",
      "                clean = 1\n",
      "            elif item == \"^\":\n",
      "                clean = 1\n",
      "            else:\n",
      "                clean = 0\n",
      "                mask.append(newmaskline)\n",
      "                break\n",
      "\n",
      "        #print mask[-1][0:50]\n",
      "        if feature.strand == 1:\n",
      "            mask[-1] = mask[-1][:featstart-1] + [\">\"] * int(featend - featstart + 1) + mask[-1][featend:]\n",
      "            if directlabel == 1:\n",
      "                mask[-1] = mask[-1][:featstart] + list(str(feature.type)) + mask[-1][featstart + len(str(feature.type)):]\n",
      "        if feature.strand == -1:\n",
      "            mask[-1] = mask[-1][:featstart-1] + [\"<\"] * int(featend+1 - featstart) + mask[-1][featend:]\n",
      "            if directlabel == 1:\n",
      "                mask[-1] = mask[-1][:featstart+1] + list(str(feature.type)) + mask[-1][featstart+2 + len(str(feature.type)):]\n",
      "\n",
      "    #if addpamcutters = 1:\n",
      "        #cutline = list(\" \" * len(inputseq)\n",
      "        #HpaIIsites = HpaII.search(inputseq.seq)\n",
      "\n",
      "\n",
      "\n",
      "    for index, maskline in enumerate(mask):\n",
      "        maskline = \"\".join(maskline)\n",
      "        mask[index] = maskline\n",
      "    # add labels\n",
      "    if directlabel == 0:\n",
      "        masklab = list(\" \" * (len(inputseq.seq)))\n",
      "        for feature in inputseq.features:\n",
      "            featstart = int(feature.location.start)\n",
      "            featend = int(feature.location.end)\n",
      "            featname = str(feature.type)\n",
      "            masklab = masklab[:featstart] + list(str(feature.type)) + list(\" \" * (featend-1 - featstart - len(feature.type))) + masklab[featend-1:]\n",
      "        masklab = \"\".join(masklab)\n",
      "\n",
      "    lines = int(round(len(inputseq.seq) / 100)) + 1\n",
      "    i = 0\n",
      "    outstring = list(inputseq.name + \"\\n\")\n",
      "    #print inputseq.name\n",
      "    outstring = []\n",
      "    while i < lines:\n",
      "        indexstart = i*100\n",
      "        indexend = (i+1) * 100\n",
      "        if indexend > len(inputseq.seq):\n",
      "            indexend = len(inputseq.seq)\n",
      "        if addpamcutters ==1:\n",
      "            outstring.extend((str(indexstart + 1)) + \"  \" + cutline[indexstart:indexend] + \"   \" + str(indexend)+ \"\\n\")\n",
      "            #print (str(indexstart + 1)) + \"  \" + cutline[indexstart:indexend] + \"   \" + str(indexend)\n",
      "        outstring.extend(str(indexstart+1) + \"  \" + inputseq.seq[indexstart:indexend] + \"   \" + str(indexend)+ \"\\n\")\n",
      "        #print str(indexstart+1) + \"  \" + inputseq.seq[indexstart:indexend] + \"   \" + str(indexend)\n",
      "        for maskline in mask:\n",
      "            outstring.extend((str(indexstart + 1)) + \"  \" + maskline[indexstart:indexend] + \"   \" + str(indexend)+ \"\\n\")\n",
      "            #print (str(indexstart + 1)) + \"  \" + maskline[indexstart:indexend] + \"   \" + str(indexend)\n",
      "        if directlabel == 0:\n",
      "            outstring.extend(str(indexstart +1) + \"  \" + masklab[indexstart:indexend] + \"   \" + str(indexend)+ \"\\n\")\n",
      "            #print str(indexstart +1) + \"  \" + masklab[indexstart:indexend] + \"   \" + str(indexend)\n",
      "        outstring.extend(\"\\n\")\n",
      "        #print \"\\n\"\n",
      "        i = i + 1\n",
      "    outstring = \"\".join(outstring)\n",
      "    return outstring"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def al_digesttarget(list_of_targets, process_to_file=0):\n",
      "    '''\n",
      "    Substrate should be a list of SeqRecords (i.e. scaffolds, or whatever).\n",
      "    Process_to_file [optional] is an integer; if 1 will avoid building list in memory and will write to file instead.\n",
      "        Defaults to 0, building list in memory.\n",
      "    Output list has information in it:\n",
      "        ID is a count of the potential spacer along the scaffold, starting from zero.\n",
      "        Name is the base position on the scaffold.\n",
      "        Description is the enzyme that generated the spacer-end (ScrFI/HpaII/BfaI)\n",
      "        dbxrefs is the name the scaffold was given in the input SeqRecord\n",
      "    '''\n",
      "    f = open(\"genome_allspacers.fa\",\"w\")\n",
      "    global substrate\n",
      "    scaffoldcuts = []\n",
      "    for substrate in list_of_targets:\n",
      "        cutslist = []\n",
      "        pos = HpaII.search(substrate.seq)\n",
      "        # Positions in this list correspond to the right boundaries of fragments; \n",
      "        # last one is thus the sequence end\n",
      "        pos.append(len(substrate.seq))\n",
      "        pos = iter(pos)\n",
      "        cuts = HpaII.catalyze(substrate.seq)\n",
      "        for item in cuts:\n",
      "            cutslist.append([item, \"HpaII\", int(pos.next())])\n",
      "\n",
      "        cuts = BfaI.catalyze(substrate.seq)\n",
      "        pos = BfaI.search(substrate.seq)\n",
      "        pos.append(len(substrate.seq))\n",
      "        pos = iter(pos)\n",
      "        for item in cuts:\n",
      "            cutslist.append([item, \"BfaI\", int(pos.next())])\n",
      "\n",
      "        cuts = ScrFI.catalyze(substrate.seq)\n",
      "        pos = ScrFI.search(substrate.seq)\n",
      "        pos.append(len(substrate.seq))\n",
      "        pos = iter(pos)\n",
      "        for item in cuts:\n",
      "            cutslist.append([item, \"ScrFI\", int(pos.next())])\n",
      "\n",
      "        #The above is all to get the results of a catalyze operation (i.e. tuples) into\n",
      "        # a list format. Next part makes them into SeqRecords.\n",
      "\n",
      "        cutslistrecords = []\n",
      "        for i, item in enumerate(cutslist):\n",
      "            cutslistrecords.append(SeqRecord(item[0], id = str(i), description = str(item[1]), name=str(item[2]), \\\n",
      "                                             dbxrefs=[str(substrate.id)]))\n",
      "        cutslist = cutslistrecords[:]\n",
      "\n",
      "        # This part takes the 3' 20nt of each fragment and makes a new sequence with it.\n",
      "        # For the 5' end, the Mung-Bean treatment is simulated by removing two more nt (for HpaII and BfaI), or one nt for ScrFI;\n",
      "        # these would be the 5' overhang. Then we take the reverse-complement of the sequence. \n",
      "        # The Restriction module just returns sequences as if the top strand only was being cut. In other words,\n",
      "        # no bases are deleted from consecutive fragments. \n",
      "\n",
      "        from Bio.Seq import MutableSeq\n",
      "        twentymers = []\n",
      "        #record2 = []\n",
      "        for record2 in cutslist:\n",
      "                try: # This is because a second run of this code on already mutable seqs seems to fail. Not sure how to flush out and revert back to non-mutables...\n",
      "                    record2.seq = record2.seq.tomutable()\n",
      "                except:\n",
      "                    pass\n",
      "                if record2.description == \"ScrFI\":\n",
      "                    #offset here (e.g. 1:21 is for simulating MBN digeston)\n",
      "                    # because the entry.names are rooted on the right of each fragment, the length\n",
      "                    # of the entry.name has to be subtracted to get the desired left position for the \"reverse\"\n",
      "                    # tgts\n",
      "                    entry = record2[1:21].reverse_complement\\\n",
      "                    (description=True, id=True, name=True)\n",
      "                    entry.name = str(int(record2.name)+1 - len(record2.seq))\n",
      "                    entry.id = str(\"%s_R\" % record2.id) ##\n",
      "                    twentymers.append(entry)\n",
      "                else: # Should work for HpaII/BfaI\n",
      "                    entry = record2[2:22].reverse_complement\\\n",
      "                    (description=True, id=True, name=True)\n",
      "                    entry.name = str(int(record2.name)+2 - len(record2.seq))\n",
      "                    entry.id = str(\"%s_R\" % record2.id) ##\n",
      "                    twentymers.append(entry)\n",
      "                record2.seq = record2.seq.toseq()\n",
      "                record2.id = str(\"%s_F\" % record2.id)\n",
      "                entry = record2[-20:]\n",
      "                entry.name = str(int(record2.name)-20)\n",
      "                twentymers.append(entry)\n",
      "\n",
      "        for item in twentymers:\n",
      "            item.dbxrefs = [substrate.id]\n",
      "\n",
      "        # The ends of the fragments aren't bonafide CRISPR targets; these can be removed:\n",
      "        noends = []\n",
      "        twentymerstr = [item for item in twentymers if item.description == \"HpaII\"]\n",
      "        trimmed = twentymerstr[1:-1] # removes first and last 20mer\n",
      "        noends.append(trimmed)\n",
      "        twentymerstr = [item for item in twentymers if item.description == \"BfaI\"]\n",
      "        trimmed = twentymerstr[1:-1]\n",
      "        noends.append(trimmed)\n",
      "        twentymerstr = [item for item in twentymers if item.description == \"ScrFI\"]\n",
      "        trimmed = twentymerstr[1:-1]\n",
      "        noends.append(trimmed)\n",
      "\n",
      "        index = str(substrate.id + str(random.random()))\n",
      "        if process_to_file != 1:\n",
      "            scaffoldcuts.append((item for sublist in noends for item in sublist))\n",
      "        if process_to_file == 1:\n",
      "            f = open(\"genome_allspacers.fa\",\"a\") #opens file with name of \"test.txt\"\n",
      "            for item in [item for sublist in noends for item in sublist]:\n",
      "                f.write(\">lcl|\" + str(substrate.id) + \"|\" + str(item.description) + \"|\" + str(item.name) + \"|\" + str(item.id) + \"\\n\")\n",
      "                f.write(str(item.seq) + \"\\n\")\n",
      "            f.close()\n",
      "    if process_to_file != 1:\n",
      "        return itertools.chain.from_iterable(scaffoldcuts) #dammit, the from_iterable part is important here. that took a while."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def al_scoreguide(guide, genome, genomedict, hits=50):\n",
      "    '''\n",
      "    To produce a score for a given guide in a given BLAST database. Returns an int, the score.\n",
      "    Only evaluates a max of 500 hit sequences (i.e. really bad guides will not necessarily have a super accurate score.)\n",
      "    This version only searches the plus strand of the BLAST db, meant to be used with PAM BLAST DBs generated such that\n",
      "    all potential guide hits are on the plus strand.\n",
      "    Arguments:  guide = a SeqRecord object containing a proposed guide sequence\n",
      "                genome = a BLAST database set up on this machine.\n",
      "                genomedict = a dict made from a FASTA file identical to the one used to make the BLAST DB. Dict keys should be\n",
      "                    BLAST db hit_def.\n",
      "    Returns: Tuple containing (finalscore, a list of the individual hits, their locations and their subscores)\n",
      "    '''\n",
      "    name = multiprocessing.current_process().name\n",
      "    M = [0, 0, 0.014, 0, 0, 0.395, 0.317, 0 ,0.389, 0.079, 0.445, 0.508, 0.613, 0.851, 0.732, 0.828, 0.615, 0.804, 0.685, 0.583]\n",
      "    #import random\n",
      "    random.jumpahead(1)\n",
      "    #filesuffix = str(int(random.random()*100000000))\n",
      "    filesuffix = str(guide.id)\n",
      "    filename = str(\"currseq\" + filesuffix + \".tmp\")\n",
      "    Bio.SeqIO.write(guide, filename, \"fasta\")\n",
      "    # Added dust=\"no\" to stop inflating scores from polyN repeats...\n",
      "    blastn_cline = NcbiblastnCommandline(query=filename, db=genome, \\\n",
      "    task = \"blastn-short\",outfmt=5, out=filename + \".blast\", max_target_seqs=100, num_threads = 7, evalue = 10, dust=\"no\")\n",
      "    #timeit.timeit(blastn_cline, number =1)\n",
      "    blastn_cline()\n",
      "    result_handle = open(filename + \".blast\")\n",
      "    hits = NCBIXML.parse(result_handle)\n",
      "    firstmatch = 0\n",
      "    notfound = 1\n",
      "    for item in hits:\n",
      "        scorelist = []\n",
      "        pamlist = []\n",
      "        for scaffold in item.alignments:\n",
      "            for pair in scaffold.hsps:\n",
      "                hit_threeprime_offset = len(guide) - pair.query_end\n",
      "                start = pair.sbjct_start\n",
      "                end = pair.sbjct_end\n",
      "                if end > start:\n",
      "                    pamstart = end + hit_threeprime_offset\n",
      "                    pam = genomedict[scaffold.hit_def][pamstart:pamstart+3]\n",
      "                elif start > end:\n",
      "                    pamstart = end - hit_threeprime_offset\n",
      "                    pam = genomedict[scaffold.hit_def][pamstart-4:pamstart-1].reverse_complement()\n",
      "                \n",
      "                # Construct a bar-based match string, padded to query length, \n",
      "                # where bar = match position and space is non-match\n",
      "                mmloc = []\n",
      "                mmstr = list(pair.match)\n",
      "                if pair.query_start > 1:\n",
      "                    mmstr = list(\" \" * (pair.query_start - 1)) + mmstr\n",
      "                if pair.query_end < 20:\n",
      "                    mmstr = mmstr + list(\" \" * (20 - pair.query_end))\n",
      "                mmstr = \"\".join(mmstr)\n",
      "\n",
      "                # Test for PAM adjacency\n",
      "                if len(pam) == 3:\n",
      "                    if (pam[1] == \"G\" or pam[1] == \"A\" or pam[1] == \"g\" or pam[1] == \"a\") \\\n",
      "                        and (pam[2] == \"G\" or pam[2] == \"g\"):\n",
      "                        if (pair.positives >16 and pair.positives < 20):\n",
      "                            pos = 20\n",
      "                            for linestring in mmstr:\n",
      "                                if linestring != \"|\":\n",
      "                                    mmloc.append(pos)\n",
      "                                pos = pos - 1\n",
      "                            \n",
      "                            # Actually implement Zhang lab algorithm\n",
      "                            mmscore = [21 -x for x in mmloc]\n",
      "                            t1 = 1\n",
      "                            for mismatchlocation in mmscore:\n",
      "                                t1 = t1 * (1.0 - float(M[mismatchlocation - 1]))\n",
      "                            if len(mmscore) > 1:\n",
      "                                d = (float(max(mmscore)) - float(min(mmscore))) / float((len(mmscore) - 1))\n",
      "                            else:\n",
      "                                d = 19\n",
      "                            t2 = 1 / ( (((19.0 - d)/19.0) * 4) + 1)\n",
      "                            t3 = float(1)/ float(pow(len(mmloc), 2))\n",
      "                            scorelist.append({\"match_score\": float(t1 * t2 * t3 * 100), \"scaffold\": scaffold.hit_def, \\\n",
      "                                              \"hit_location\":pair.sbjct_start, \"hit_sequence\": pair.sbjct, \"pam\":str(pam.seq),\\\n",
      "                                              \"match_bars\":mmstr})\n",
      "                            #pamlist.append(pam)\n",
      "                        # Zhang lab algorithm doesn't handle perfect matches (I think?): give it a 50 if it's perfect\n",
      "                        if pair.positives >= 20: #changed from == 20; miight be worth keeping in mind for bugs\n",
      "                            if firstmatch != 0:\n",
      "                                scorelist.append({\"match_score\": float(50), \"scaffold\": scaffold.hit_def, \\\n",
      "                                                  \"hit_location\":pair.sbjct_start, \"hit_sequence\": pair.sbjct, \"pam\":str(pam.seq),\\\n",
      "                                                  \"match_bars\":mmstr})\n",
      "                                #pamlist.append(pam)\n",
      "                            firstmatch = 1\n",
      "                            notfound = 0\n",
      "                    else: \n",
      "                        scorelist.append({\"match_score\": float(0), \"scaffold\": scaffold.hit_def, \\\n",
      "                                          \"hit_location\":pair.sbjct_start, \"hit_sequence\": pair.sbjct, \"pam\":str(pam.seq),\\\n",
      "                                          \"match_bars\":mmstr})\n",
      "                        #pamlist.append(pam)\n",
      "    os.remove(filename) # want to keep BLAST results? comment out these two lines.\n",
      "    os.remove(filename + \".blast\")\n",
      "    # Only include the scorelist items that have a score greater than zero\n",
      "    guide.annotations[\"blastdata\"] = [s for s in scorelist if s[\"match_score\"] > 0]\n",
      "    finalscore = int(10000.000 / (100.000 + float(sum(item[\"match_score\"] for item in scorelist))))\n",
      "    guide.annotations[\"score\"] = finalscore\n",
      "    return guide"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def al_scoremanyguides(guides, genome, genomedict, hits=50, return_blast =1):\n",
      "    '''\n",
      "    To produce a score for a given guide in a given BLAST database. Returns an int, the score.\n",
      "    Only evaluates a max of 500 hit sequences (i.e. really bad guides will not necessarily have a super accurate score.)\n",
      "    This version only searches the plus strand of the BLAST db, meant to be used with PAM BLAST DBs generated such that\n",
      "    all potential guide hits are on the plus strand.\n",
      "    Arguments:  guide = a SeqRecord object containing a proposed guide sequence\n",
      "                genome = a BLAST database set up on this machine.\n",
      "                genomedict = a dict made from a FASTA file identical to the one used to make the BLAST DB. Dict keys should be\n",
      "                    BLAST db hit_def.\n",
      "    Returns: Tuple containing (finalscore, a list of the individual hits, their locations and their subscores)\n",
      "    '''\n",
      "    name = multiprocessing.current_process().name\n",
      "    M = [0, 0, 0.014, 0, 0, 0.395, 0.317, 0 ,0.389, 0.079, 0.445, 0.508, 0.613, 0.851, 0.732, 0.828, 0.615, 0.804, 0.685, 0.583]\n",
      "    #import random\n",
      "    random.jumpahead(1)\n",
      "    #filesuffix = str(int(random.random()*100000000))\n",
      "    filesuffix = str(guides[0].id)\n",
      "    filename = str(\"currseq\" + filesuffix + \".tmp\")\n",
      "    Bio.SeqIO.write(guides, filename, \"fasta\")\n",
      "    # Added dust=\"no\" to stop inflating scores from polyN repeats...\n",
      "    blastn_cline = NcbiblastnCommandline(query=filename, db=genome, \\\n",
      "    task = \"blastn-short\",outfmt=5, out=filename + \".blast\", max_target_seqs=100, num_threads = 7, evalue = 10, dust=\"no\")\n",
      "    #timeit.timeit(blastn_cline, number =1)\n",
      "    blastn_cline()\n",
      "    result_handle = open(filename + \".blast\")\n",
      "    blasts = NCBIXML.parse(result_handle)\n",
      "    # This generates an generator of BLAST objects, each corresponding to a guide query. Loop through those.\n",
      "    for guideindex, item in enumerate(blasts):\n",
      "        firstmatch = 0\n",
      "        notfound = 1\n",
      "        scorelist = []\n",
      "        pamlist = []\n",
      "        # Within each queried guide, loop through the aligned scaffolds\n",
      "        for scaffold in item.alignments:\n",
      "            # Within each aligned scaffold, loop through invidivual HSPs on that scaffold.\n",
      "            for pair in scaffold.hsps:\n",
      "                hit_threeprime_offset = len(guides[0]) - pair.query_end\n",
      "                start = pair.sbjct_start\n",
      "                end = pair.sbjct_end\n",
      "                if end > start:\n",
      "                    pamstart = end + hit_threeprime_offset\n",
      "                    pam = genomedict[scaffold.hit_def][pamstart:pamstart+3]\n",
      "                elif start > end:\n",
      "                    pamstart = end - hit_threeprime_offset\n",
      "                    pam = genomedict[scaffold.hit_def][pamstart-4:pamstart-1].reverse_complement()\n",
      "\n",
      "                # Construct a bar-based match string, padded to query length, \n",
      "                # where bar = match position and space is non-match\n",
      "                mmloc = []\n",
      "                mmstr = list(pair.match)\n",
      "                if pair.query_start > 1:\n",
      "                    mmstr = list(\" \" * (pair.query_start - 1)) + mmstr\n",
      "                if pair.query_end < 20:\n",
      "                    mmstr = mmstr + list(\" \" * (20 - pair.query_end))\n",
      "                mmstr = \"\".join(mmstr)\n",
      "\n",
      "                # Test for PAM adjacency\n",
      "                if len(pam) == 3:\n",
      "                    if (pam[1] == \"G\" or pam[1] == \"A\" or pam[1] == \"g\" or pam[1] == \"a\") \\\n",
      "                        and (pam[2] == \"G\" or pam[2] == \"g\"):\n",
      "                        if (pair.positives >16 and pair.positives < 20):\n",
      "                            pos = 20\n",
      "                            for linestring in mmstr:\n",
      "                                if linestring != \"|\":\n",
      "                                    mmloc.append(pos)\n",
      "                                pos = pos - 1\n",
      "\n",
      "                            # Actually implement Zhang lab algorithm\n",
      "                            mmscore = [21 -x for x in mmloc]\n",
      "                            t1 = 1\n",
      "                            for mismatchlocation in mmscore:\n",
      "                                t1 = t1 * (1.0 - float(M[mismatchlocation - 1]))\n",
      "                            if len(mmscore) > 1:\n",
      "                                d = (float(max(mmscore)) - float(min(mmscore))) / float((len(mmscore) - 1))\n",
      "                            else:\n",
      "                                d = 19\n",
      "                            t2 = 1 / ( (((19.0 - d)/19.0) * 4) + 1)\n",
      "                            t3 = float(1)/ float(pow(len(mmloc), 2))\n",
      "                            scorelist.append({\"match_score\": float(t1 * t2 * t3 * 100), \"scaffold\": scaffold.hit_def, \\\n",
      "                                              \"hit_location\":pair.sbjct_start, \"hit_sequence\": pair.sbjct, \"pam\":str(pam.seq),\\\n",
      "                                              \"match_bars\":mmstr})\n",
      "                            #pamlist.append(pam)\n",
      "                        # Zhang lab algorithm doesn't handle perfect matches (I think?): give it a 50 if it's perfect\n",
      "                        if pair.positives >= 20: #changed from == 20; miight be worth keeping in mind for bugs\n",
      "                            if firstmatch != 0:\n",
      "                                scorelist.append({\"match_score\": float(50), \"scaffold\": scaffold.hit_def, \\\n",
      "                                                  \"hit_location\":pair.sbjct_start, \"hit_sequence\": pair.sbjct, \"pam\":str(pam.seq),\\\n",
      "                                                  \"match_bars\":mmstr})\n",
      "                                #pamlist.append(pam)\n",
      "                            firstmatch = 1\n",
      "                            notfound = 0\n",
      "                    else: \n",
      "                        scorelist.append({\"match_score\": float(0), \"scaffold\": scaffold.hit_def, \\\n",
      "                                          \"hit_location\":pair.sbjct_start, \"hit_sequence\": pair.sbjct, \"pam\":str(pam.seq),\\\n",
      "                                          \"match_bars\":mmstr})\n",
      "                        #pamlist.append(pam)\n",
      "        # Only include the scorelist items that have a score greater than zero\n",
      "        if return_blast == 1:\n",
      "            guides[guideindex].annotations[\"blastdata\"] = [s for s in scorelist if s[\"match_score\"] > 0]\n",
      "        finalscore = int(10000.000 / (100.000 + float(sum(item[\"match_score\"] for item in scorelist))))\n",
      "        guides[guideindex].annotations[\"score\"] = finalscore\n",
      "    \n",
      "    os.remove(filename) # want to keep BLAST results? comment out these two lines.\n",
      "    os.remove(filename + \".blast\")\n",
      "\n",
      "    #return hits\n",
      "    return guides"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def al_scoreguide_density(guide, genome, genomedict, hits=50):\n",
      "    '''\n",
      "    To produce a score for a given guide in a given BLAST database. Returns an int, the score.\n",
      "    Only evaluates a max of 500 hit sequences (i.e. really bad guides will not necessarily have a super accurate score.)\n",
      "    This version only searches the plus strand of the BLAST db, meant to be used with PAM BLAST DBs generated such that\n",
      "    all potential guide hits are on the plus strand.\n",
      "    Arguments:  guide = a SeqRecord object containing a proposed guide sequence\n",
      "                genome = a BLAST database set up on this machine.\n",
      "                genomedict = a dict made from a FASTA file identical to the one used to make the BLAST DB. Dict keys should be\n",
      "                    BLAST db hit_def.\n",
      "    Returns: Tuple containing (finalscore, a list of the individual hits, their locations and their subscores)\n",
      "    '''\n",
      "    name = multiprocessing.current_process().name\n",
      "    M = [0, 0, 0.014, 0, 0, 0.395, 0.317, 0 ,0.389, 0.079, 0.445, 0.508, 0.613, 0.851, 0.732, 0.828, 0.615, 0.804, 0.685, 0.583]\n",
      "    import random\n",
      "    random.jumpahead(1)\n",
      "    #filesuffix = str(int(random.random()*100000000))\n",
      "    filesuffix = str(guide.id)\n",
      "    filename = str(\"currseq\" + filesuffix + \".tmp\")\n",
      "    Bio.SeqIO.write(guide, filename, \"fasta\")\n",
      "    blastn_cline = NcbiblastnCommandline(query=filename, db=genome, \\\n",
      "    task = \"blastn-short\",outfmt=5, out=filename + \".blast\", max_target_seqs=100, num_threads = 7, evalue = 100)\n",
      "    #timeit.timeit(blastn_cline, number =1)\n",
      "    blastn_cline()\n",
      "    result_handle = open(filename + \".blast\")\n",
      "    hits = NCBIXML.parse(result_handle)\n",
      "    firstmatch = 0\n",
      "    notfound = 1\n",
      "    for item in hits:\n",
      "        scorelist = []\n",
      "        pamlist = []\n",
      "        for scaffold in item.alignments:\n",
      "            for pair in scaffold.hsps:\n",
      "                hit_threeprime_offset = len(guide) - pair.query_end\n",
      "                start = pair.sbjct_start\n",
      "                end = pair.sbjct_end\n",
      "                if end > start:\n",
      "                    pamstart = end + hit_threeprime_offset\n",
      "                    pam = genomedict[scaffold.hit_def][pamstart:pamstart+3]\n",
      "                elif start > end:\n",
      "                    pamstart = end - hit_threeprime_offset\n",
      "                    pam = genomedict[scaffold.hit_def][pamstart-4:pamstart-1].reverse_complement()\n",
      "                if len(pam) == 3:\n",
      "                    t1 = 0\n",
      "                    t2 = 0\n",
      "                    t3=0\n",
      "                    if (pam[1] == \"G\" or pam[1] == \"A\" or pam[1] == \"g\" or pam[1] == \"a\") \\\n",
      "                        and (pam[2] == \"G\" or pam[2] == \"g\"):\n",
      "                        if (pair.positives >12 and pair.positives < 20):\n",
      "                            mmloc = []\n",
      "                            mmstr = list(pair.match)\n",
      "                            if pair.query_start > 1:\n",
      "                                mmstr = list(\" \" * (pair.query_start - 1)) + mmstr\n",
      "                            if pair.query_end < 20:\n",
      "                                mmstr = mmstr + list(\" \" * (20 - pair.query_end))\n",
      "                            \"\".join(mmstr)\n",
      "                            pos = 20\n",
      "                            for linestring in mmstr:\n",
      "                                if linestring != \"|\":\n",
      "                                    mmloc.append(pos)\n",
      "                                pos = pos - 1\n",
      "\n",
      "                            mmscore = [21 -x for x in mmloc]\n",
      "                            t1 = 1\n",
      "                            for mismatchlocation in mmscore:\n",
      "                                t1 = t1 * (1.0 - float(M[mismatchlocation - 1]))\n",
      "                            if len(mmscore) > 1:\n",
      "                                d = (float(max(mmscore)) - float(min(mmscore))) / float((len(mmscore) - 1))\n",
      "                            else:\n",
      "                                d = 19\n",
      "                            t2 = 1 / ( (((19.0 - d)/19.0) * 4) + 1)\n",
      "                            t3 = float(1)/ float(pow(len(mmloc), 2))\n",
      "                            scorelist.append([float(t1 * t2 * t3 * 100), ((t1, t2, t3), scaffold.hit_def, pair.sbjct_start, pair.sbjct)])\n",
      "                            #pamlist.append(pam)\n",
      "                        if pair.positives >= 20: #changed from == 20; miight be worth keeping in mind for bugs\n",
      "                            scorelist.append([float(100), ((t1, t2, t3), scaffold.hit_def, pair.sbjct_start, pair.sbjct)])\n",
      "                            notfound = 0\n",
      "                    else: \n",
      "                        scorelist.append([float(0), ((t1, t2, t3), scaffold.hit_def, pair.sbjct_start, pair.sbjct)])\n",
      "                        #pamlist.append(pam)\n",
      "    os.remove(filename) # want to keep BLAST results? comment out these two lines.\n",
      "    os.remove(filename + \".blast\")\n",
      "    finalscore = int(10000.000 / (100.000 + float(sum(score for score, details in scorelist))))\n",
      "    return (finalscore, guide, scorelist)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}